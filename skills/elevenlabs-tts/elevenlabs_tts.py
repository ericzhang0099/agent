#!/usr/bin/env python3
"""
ElevenLabsè¯­éŸ³åˆæˆç³»ç»Ÿ v1.1
é«˜è´¨é‡TTS + å¤šå£°éŸ³ + 16ç§æƒ…æ„Ÿæ§åˆ¶ + è·¨æ¨¡æ€ä¸€è‡´æ€§éªŒè¯
é€‚é… elevenlabs Python SDK v2.x
"""

import os
import json
import hashlib
from typing import Optional, Dict, Any, Iterator, List
from datetime import datetime

# å°è¯•å¯¼å…¥elevenlabs v2.x
try:
    from elevenlabs import ElevenLabs, VoiceSettings, play, save
    from elevenlabs.client import ElevenLabs as ElevenLabsClient
    ELEVENLABS_AVAILABLE = True
except ImportError:
    ELEVENLABS_AVAILABLE = False
    print("âš ï¸ è­¦å‘Š: elevenlabs æœªå®‰è£…ï¼Œè¿è¡Œ: pip install elevenlabs")

# å°è¯•åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_path):
        load_dotenv(env_path)
except ImportError:
    pass

class ElevenLabsTTS:
    """ElevenLabsè¯­éŸ³åˆæˆç³»ç»Ÿ - æ”¯æŒ16ç§æƒ…æ„Ÿæ˜ å°„"""
    
    # é¢„è®¾å£°éŸ³é…ç½® - 12ç§å£°éŸ³ï¼ˆ6ç”·6å¥³ï¼‰
    VOICES = {
        # å¥³å£°
        'Bella': {'name': 'Bella', 'gender': 'female', 'style': 'æ¸©æš–ã€è‡ªç„¶', 'locale': 'en-US'},
        'Rachel': {'name': 'Rachel', 'gender': 'female', 'style': 'å‹å¥½ã€æ´»æ³¼', 'locale': 'en-US'},
        'Elli': {'name': 'Elli', 'gender': 'female', 'style': 'å¹´è½»ã€æ´»åŠ›', 'locale': 'en-US'},
        'Alice': {'name': 'Alice', 'gender': 'female', 'style': 'ä¼˜é›…ã€çŸ¥æ€§', 'locale': 'en-GB'},
        'Domi': {'name': 'Domi', 'gender': 'female', 'style': 'ä¸“ä¸šã€è‡ªä¿¡', 'locale': 'en-US'},
        'Grace': {'name': 'Grace', 'gender': 'female', 'style': 'æ¸©æŸ”ã€äº²åˆ‡', 'locale': 'en-US'},
        # ç”·å£°
        'Adam': {'name': 'Adam', 'gender': 'male', 'style': 'ä¸“ä¸šã€æ¸…æ™°', 'locale': 'en-US'},
        'Antoni': {'name': 'Antoni', 'gender': 'male', 'style': 'æ·±æ²‰ã€ç¨³é‡', 'locale': 'en-US'},
        'Josh': {'name': 'Josh', 'gender': 'male', 'style': 'éšæ„ã€äº²åˆ‡', 'locale': 'en-US'},
        'Sam': {'name': 'Sam', 'gender': 'male', 'style': 'å¹´è½»ã€æ´»åŠ›', 'locale': 'en-US'},
        'Thomas': {'name': 'Thomas', 'gender': 'male', 'style': 'æƒå¨ã€æ­£å¼', 'locale': 'en-GB'},
        'Michael': {'name': 'Michael', 'gender': 'male', 'style': 'æ¸©æš–ã€å¯ä¿¡', 'locale': 'en-US'},
    }
    
    # 16ç§æƒ…æ„Ÿé£æ ¼æ˜ å°„ï¼ˆé€šè¿‡stability/similarity/styleè°ƒæ•´ï¼‰
    EMOTIONS = {
        # åŸºç¡€æƒ…æ„Ÿ
        'neutral': {
            'name': 'ä¸­æ€§',
            'name_en': 'neutral',
            'stability': 0.50, 
            'similarity_boost': 0.75, 
            'style': 0.00,
            'description': 'æ ‡å‡†ã€è‡ªç„¶çš„è¯­éŸ³é£æ ¼'
        },
        'calm': {
            'name': 'å¹³é™',
            'name_en': 'calm',
            'stability': 0.80, 
            'similarity_boost': 0.60, 
            'style': -0.30,
            'description': 'æ”¾æ¾ã€èˆ’ç¼“çš„è¯­è°ƒ'
        },
        'gentle': {
            'name': 'æ¸©å’Œ',
            'name_en': 'gentle',
            'stability': 0.70, 
            'similarity_boost': 0.65, 
            'style': -0.20,
            'description': 'æŸ”å’Œã€å‹å–„çš„è¡¨è¾¾'
        },
        # ç§¯ææƒ…æ„Ÿ
        'happy': {
            'name': 'å¼€å¿ƒ',
            'name_en': 'happy',
            'stability': 0.40, 
            'similarity_boost': 0.80, 
            'style': 0.40,
            'description': 'æ„‰æ‚¦ã€å¿«ä¹çš„æƒ…ç»ª'
        },
        'excited': {
            'name': 'å…´å¥‹',
            'name_en': 'excited',
            'stability': 0.30, 
            'similarity_boost': 0.80, 
            'style': 0.60,
            'description': 'æ¿€åŠ¨ã€çƒ­æƒ…çš„è¡¨è¾¾'
        },
        'optimistic': {
            'name': 'ä¹è§‚',
            'name_en': 'optimistic',
            'stability': 0.45, 
            'similarity_boost': 0.78, 
            'style': 0.35,
            'description': 'ç§¯æã€å‘ä¸Šçš„æ€åº¦'
        },
        'friendly': {
            'name': 'å‹å¥½',
            'name_en': 'friendly',
            'stability': 0.40, 
            'similarity_boost': 0.80, 
            'style': 0.20,
            'description': 'äº²åˆ‡ã€çƒ­æƒ…çš„è¯­æ°”'
        },
        'humorous': {
            'name': 'å¹½é»˜',
            'name_en': 'humorous',
            'stability': 0.35, 
            'similarity_boost': 0.75, 
            'style': 0.45,
            'description': 'è½»æ¾ã€è¯™è°çš„é£æ ¼'
        },
        # ä¸“ä¸šæƒ…æ„Ÿ
        'serious': {
            'name': 'ä¸¥è‚ƒ',
            'name_en': 'serious',
            'stability': 0.75, 
            'similarity_boost': 0.70, 
            'style': -0.20,
            'description': 'æ­£å¼ã€åº„é‡çš„è¯­è°ƒ'
        },
        'professional': {
            'name': 'ä¸“ä¸š',
            'name_en': 'professional',
            'stability': 0.70, 
            'similarity_boost': 0.72, 
            'style': 0.00,
            'description': 'å•†åŠ¡ã€æƒå¨çš„è¡¨è¾¾'
        },
        'authoritative': {
            'name': 'æƒå¨',
            'name_en': 'authoritative',
            'stability': 0.80, 
            'similarity_boost': 0.75, 
            'style': -0.10,
            'description': 'å‘½ä»¤ã€é¢†å¯¼çš„è¯­æ°”'
        },
        'confident': {
            'name': 'è‡ªä¿¡',
            'name_en': 'confident',
            'stability': 0.60, 
            'similarity_boost': 0.80, 
            'style': 0.15,
            'description': 'åšå®šã€ç¡®ä¿¡çš„è¡¨è¾¾'
        },
        # ç‰¹æ®Šæƒ…æ„Ÿ
        'mysterious': {
            'name': 'ç¥ç§˜',
            'name_en': 'mysterious',
            'stability': 0.55, 
            'similarity_boost': 0.55, 
            'style': 0.10,
            'description': 'æ‚¬ç–‘ã€æš—ç¤ºçš„é£æ ¼'
        },
        'sad': {
            'name': 'æ‚²ä¼¤',
            'name_en': 'sad',
            'stability': 0.65, 
            'similarity_boost': 0.50, 
            'style': -0.40,
            'description': 'ä½æ²‰ã€å¿§éƒçš„è¯­è°ƒ'
        },
        'angry': {
            'name': 'æ„¤æ€’',
            'name_en': 'angry',
            'stability': 0.25, 
            'similarity_boost': 0.85, 
            'style': 0.50,
            'description': 'å¼ºçƒˆã€æ¿€åŠ¨çš„æƒ…ç»ª'
        },
        'fearful': {
            'name': 'ææƒ§',
            'name_en': 'fearful',
            'stability': 0.20, 
            'similarity_boost': 0.60, 
            'style': 0.30,
            'description': 'ç´§å¼ ã€ä¸å®‰çš„è¡¨è¾¾'
        },
        'whisper': {
            'name': 'è€³è¯­',
            'name_en': 'whisper',
            'stability': 0.60, 
            'similarity_boost': 0.50, 
            'style': -0.50,
            'description': 'ç§å¯†ã€è½»å£°çš„é£æ ¼'
        },
    }
    
    # æƒ…æ„Ÿåˆ†ç±»
    EMOTION_CATEGORIES = {
        'basic': ['neutral', 'calm', 'gentle'],
        'positive': ['happy', 'excited', 'optimistic', 'friendly', 'humorous'],
        'professional': ['serious', 'professional', 'authoritative', 'confident'],
        'special': ['mysterious', 'sad', 'angry', 'fearful', 'whisper']
    }
    
    # é»˜è®¤æ¨¡å‹
    DEFAULT_MODEL = "eleven_multilingual_v2"
    
    def __init__(self, 
                 api_key: str = None,
                 voice: str = None,
                 model: str = None,
                 cache_dir: str = None,
                 auto_cache: bool = True,
                 default_emotion: str = "neutral"):
        """
        åˆå§‹åŒ–ElevenLabs TTS
        
        Args:
            api_key: APIå¯†é’¥ï¼ˆå¦‚ä¸æä¾›ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            voice: é»˜è®¤å£°éŸ³ï¼ˆé»˜è®¤ä»ç¯å¢ƒå˜é‡æˆ–Bellaï¼‰
            model: TTSæ¨¡å‹
            cache_dir: ç¼“å­˜ç›®å½•
            auto_cache: æ˜¯å¦è‡ªåŠ¨ç¼“å­˜
            default_emotion: é»˜è®¤æƒ…æ„Ÿ
        """
        self.api_key = api_key or os.getenv('ELEVENLABS_API_KEY')
        self.default_voice = voice or os.getenv('ELEVENLABS_DEFAULT_VOICE', 'Bella')
        self.default_emotion = default_emotion or os.getenv('ELEVENLABS_DEFAULT_EMOTION', 'neutral')
        self.model = model or os.getenv('ELEVENLABS_MODEL', self.DEFAULT_MODEL)
        self.cache_dir = cache_dir or os.getenv('ELEVENLABS_CACHE_DIR', './tts_cache')
        self.auto_cache = auto_cache
        
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # çŠ¶æ€
        self.status = "configured"
        self.last_error = None
        self.stats = {
            'synthesis_count': 0,
            'cache_hits': 0,
            'errors': 0
        }
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.client = None
        if ELEVENLABS_AVAILABLE and self.api_key:
            try:
                self.client = ElevenLabsClient(api_key=self.api_key)
                self.status = "ready"
            except Exception as e:
                self.status = "error"
                self.last_error = str(e)
        elif not ELEVENLABS_AVAILABLE:
            self.status = "missing_dependency"
        elif not self.api_key:
            self.status = "missing_api_key"
    
    def synthesize(self, 
                   text: str,
                   voice: str = None,
                   emotion: str = None,
                   speed: float = 1.0,
                   output_path: str = None) -> Dict[str, Any]:
        """
        åˆæˆè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice: å£°éŸ³IDï¼ˆé»˜è®¤ä½¿ç”¨åˆå§‹åŒ–è®¾ç½®ï¼‰
            emotion: æƒ…æ„Ÿé£æ ¼ï¼ˆ16ç§ä¹‹ä¸€ï¼‰
            speed: è¯­é€Ÿï¼ˆ0.5-2.0ï¼‰
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            dict: åŒ…å«éŸ³é¢‘è·¯å¾„å’Œå…ƒæ•°æ®
        """
        if self.status != "ready":
            return {
                'success': False,
                'error': f"TTSæœªå°±ç»ª: {self.status}",
                'text': text
            }
        
        voice = voice or self.default_voice
        emotion = emotion or self.default_emotion
        
        # éªŒè¯æƒ…æ„Ÿ
        if emotion not in self.EMOTIONS:
            return {
                'success': False,
                'error': f"æ— æ•ˆçš„æƒ…æ„Ÿ: {emotion}ï¼Œå¯ç”¨: {list(self.EMOTIONS.keys())}",
                'text': text
            }
        
        # æ£€æŸ¥ç¼“å­˜
        if self.auto_cache:
            cached = self._get_cache(text, voice, emotion, speed)
            if cached:
                self.stats['cache_hits'] += 1
                return {
                    'success': True,
                    'audio_path': cached,
                    'cached': True,
                    'text': text,
                    'voice': voice,
                    'emotion': emotion,
                    'emotion_params': self.EMOTIONS[emotion]
                }
        
        # è·å–æƒ…æ„Ÿå‚æ•°
        emotion_params = self.EMOTIONS[emotion]
        
        try:
            # ç”ŸæˆéŸ³é¢‘ (elevenlabs v2.x API)
            voice_settings = VoiceSettings(
                stability=emotion_params['stability'],
                similarity_boost=emotion_params['similarity_boost'],
                style=emotion_params['style'] + (speed - 1.0) * 0.3
            )
            
            audio = self.client.text_to_speech.convert(
                text=text,
                voice_id=voice,
                model_id=self.model,
                voice_settings=voice_settings
            )
            
            # ç¡®å®šè¾“å‡ºè·¯å¾„
            if output_path is None:
                output_path = self._generate_cache_path(text, voice, emotion, speed)
            
            # ä¿å­˜éŸ³é¢‘
            save(audio, output_path)
            
            self.stats['synthesis_count'] += 1
            
            return {
                'success': True,
                'audio_path': output_path,
                'cached': False,
                'text': text,
                'voice': voice,
                'emotion': emotion,
                'emotion_params': emotion_params,
                'duration_estimate': len(text) * 0.3  # ç²—ç•¥ä¼°è®¡
            }
            
        except Exception as e:
            self.stats['errors'] += 1
            self.last_error = str(e)
            return {
                'success': False,
                'error': str(e),
                'text': text
            }
    
    def synthesize_stream(self, 
                         text: str,
                         voice: str = None,
                         emotion: str = None) -> Iterator[bytes]:
        """
        æµå¼åˆæˆï¼ˆé€‚åˆé•¿æ–‡æœ¬ï¼‰
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            voice: å£°éŸ³ID
            emotion: æƒ…æ„Ÿé£æ ¼
            
        Yields:
            bytes: éŸ³é¢‘æ•°æ®å—
        """
        if self.status != "ready":
            raise RuntimeError(f"TTSæœªå°±ç»ª: {self.status}")
        
        voice = voice or self.default_voice
        emotion = emotion or self.default_emotion
        emotion_params = self.EMOTIONS.get(emotion, self.EMOTIONS['neutral'])
        
        # æµå¼ç”Ÿæˆ (elevenlabs v2.x API)
        voice_settings = VoiceSettings(
            stability=emotion_params['stability'],
            similarity_boost=emotion_params['similarity_boost'],
            style=emotion_params['style']
        )
        
        audio_stream = self.client.text_to_speech.convert_as_stream(
            text=text,
            voice_id=voice,
            model_id=self.model,
            voice_settings=voice_settings
        )
        
        for chunk in audio_stream:
            yield chunk
    
    def synthesize_batch(self,
                        texts: List[str],
                        voice: str = None,
                        emotion: str = None) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆæˆ
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            voice: å£°éŸ³ID
            emotion: æƒ…æ„Ÿé£æ ¼
            
        Returns:
            list: åˆæˆç»“æœåˆ—è¡¨
        """
        results = []
        for text in texts:
            result = self.synthesize(text, voice=voice, emotion=emotion)
            results.append(result)
        return results
    
    def validate_emotion_mapping(self, emotion: str) -> Dict[str, Any]:
        """
        éªŒè¯æƒ…æ„Ÿæ˜ å°„çš„è·¨æ¨¡æ€ä¸€è‡´æ€§
        
        Args:
            emotion: æƒ…æ„Ÿåç§°
            
        Returns:
            dict: éªŒè¯ç»“æœ
        """
        if emotion not in self.EMOTIONS:
            return {
                'emotion': emotion,
                'valid': False,
                'error': f'æ— æ•ˆæƒ…æ„Ÿï¼Œå¯ç”¨: {list(self.EMOTIONS.keys())}'
            }
        
        params = self.EMOTIONS[emotion]
        
        # éªŒè¯å‚æ•°èŒƒå›´
        validations = {
            'stability_range': 0 <= params['stability'] <= 1,
            'similarity_range': 0 <= params['similarity_boost'] <= 1,
            'style_range': -1 <= params['style'] <= 1
        }
        
        # æƒ…æ„Ÿä¸€è‡´æ€§æ£€æŸ¥
        consistency_checks = self._check_emotion_consistency(emotion, params)
        
        return {
            'emotion': emotion,
            'valid': all(validations.values()),
            'params': params,
            'validations': validations,
            'consistency': consistency_checks,
            'category': self._get_emotion_category(emotion)
        }
    
    def _check_emotion_consistency(self, emotion: str, params: Dict) -> Dict[str, Any]:
        """æ£€æŸ¥æƒ…æ„Ÿå‚æ•°ä¸€è‡´æ€§"""
        checks = {}
        
        # ç¨³å®šæ€§ä¸æƒ…æ„Ÿç±»å‹çš„å…³ç³»
        if emotion in ['calm', 'serious', 'authoritative']:
            checks['stability_match'] = params['stability'] >= 0.6
        elif emotion in ['excited', 'angry', 'fearful']:
            checks['stability_match'] = params['stability'] <= 0.4
        else:
            checks['stability_match'] = True
        
        # é£æ ¼å€¼ä¸æƒ…æ„Ÿç±»å‹çš„å…³ç³»
        if emotion in ['happy', 'excited', 'humorous', 'angry']:
            checks['style_match'] = params['style'] > 0
        elif emotion in ['calm', 'sad', 'whisper', 'serious']:
            checks['style_match'] = params['style'] < 0
        else:
            checks['style_match'] = True
        
        return checks
    
    def _get_emotion_category(self, emotion: str) -> str:
        """è·å–æƒ…æ„Ÿåˆ†ç±»"""
        for category, emotions in self.EMOTION_CATEGORIES.items():
            if emotion in emotions:
                return category
        return 'unknown'
    
    def test_all_emotions(self, text: str = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•è¯­éŸ³ï¼Œç”¨äºéªŒè¯ä¸åŒæƒ…æ„Ÿé£æ ¼çš„æ•ˆæœã€‚") -> List[Dict[str, Any]]:
        """
        æµ‹è¯•æ‰€æœ‰16ç§æƒ…æ„Ÿ
        
        Args:
            text: æµ‹è¯•æ–‡æœ¬
            
        Returns:
            list: æ‰€æœ‰æƒ…æ„Ÿçš„æµ‹è¯•ç»“æœ
        """
        results = []
        print(f"ğŸ§ª æµ‹è¯•æ‰€æœ‰16ç§æƒ…æ„Ÿï¼Œæ–‡æœ¬: {text}")
        print("=" * 60)
        
        for emotion in self.EMOTIONS.keys():
            print(f"  æµ‹è¯•æƒ…æ„Ÿ: {emotion}...", end=" ")
            
            # éªŒè¯æ˜ å°„
            validation = self.validate_emotion_mapping(emotion)
            
            # å°è¯•åˆæˆï¼ˆå¦‚æœAPIå·²é…ç½®ï¼‰
            synthesis_result = None
            if self.status == "ready":
                synthesis_result = self.synthesize(text, emotion=emotion)
            
            result = {
                'emotion': emotion,
                'validation': validation,
                'synthesis': synthesis_result
            }
            results.append(result)
            
            status = "âœ…" if validation['valid'] else "âŒ"
            print(f"{status}")
        
        print("=" * 60)
        print(f"âœ… æµ‹è¯•å®Œæˆ: {len(results)} ç§æƒ…æ„Ÿ")
        return results
    
    def _generate_cache_path(self, text: str, voice: str, emotion: str, speed: float) -> str:
        """ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        content = f"{text}|{voice}|{emotion}|{speed}"
        hash_val = hashlib.md5(content.encode()).hexdigest()[:12]
        filename = f"{voice}_{emotion}_{hash_val}.mp3"
        return os.path.join(self.cache_dir, filename)
    
    def _get_cache(self, text: str, voice: str, emotion: str, speed: float) -> Optional[str]:
        """æ£€æŸ¥ç¼“å­˜"""
        cache_path = self._generate_cache_path(text, voice, emotion, speed)
        if os.path.exists(cache_path):
            return cache_path
        return None
    
    def get_voices(self) -> Dict[str, Any]:
        """è·å–å¯ç”¨å£°éŸ³åˆ—è¡¨"""
        if self.status == "ready" and self.client:
            try:
                available_voices = self.client.voices.get_all()
                voice_names = [v.name for v in available_voices.voices] if hasattr(available_voices, 'voices') else []
                return {
                    'preset': self.VOICES,
                    'preset_count': len(self.VOICES),
                    'available': voice_names,
                    'available_count': len(voice_names)
                }
            except Exception as e:
                return {
                    'preset': self.VOICES,
                    'preset_count': len(self.VOICES),
                    'available': [],
                    'error': str(e)
                }
        return {
            'preset': self.VOICES,
            'preset_count': len(self.VOICES),
            'available': [],
            'status': self.status
        }
    
    def get_emotions(self) -> Dict[str, Any]:
        """è·å–å¯ç”¨æƒ…æ„Ÿåˆ—è¡¨"""
        return {
            'emotions': self.EMOTIONS,
            'count': len(self.EMOTIONS),
            'categories': self.EMOTION_CATEGORIES
        }
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            'status': self.status,
            'api_key_configured': bool(self.api_key),
            'api_key_preview': self.api_key[:8] + '...' if self.api_key else None,
            'default_voice': self.default_voice,
            'default_emotion': self.default_emotion,
            'model': self.model,
            'cache_dir': self.cache_dir,
            'last_error': self.last_error,
            'elevenlabs_available': ELEVENLABS_AVAILABLE,
            'stats': self.stats,
            'voices_count': len(self.VOICES),
            'emotions_count': len(self.EMOTIONS)
        }
    
    def configure_api_key(self, api_key: str) -> Dict[str, Any]:
        """é…ç½®APIå¯†é’¥"""
        self.api_key = api_key
        os.environ['ELEVENLABS_API_KEY'] = api_key
        
        if ELEVENLABS_AVAILABLE:
            try:
                self.client = ElevenLabsClient(api_key=api_key)
                self.status = "ready"
                return {'success': True, 'status': 'ready'}
            except Exception as e:
                self.status = "error"
                self.last_error = str(e)
                return {'success': False, 'error': str(e)}
        else:
            return {'success': False, 'error': 'elevenlabsåº“æœªå®‰è£…'}
    
    def clear_cache(self) -> Dict[str, Any]:
        """æ¸…é™¤ç¼“å­˜"""
        count = 0
        for filename in os.listdir(self.cache_dir):
            if filename.endswith('.mp3'):
                os.remove(os.path.join(self.cache_dir, filename))
                count += 1
        return {'success': True, 'cleared_files': count}

# å…¨å±€å®ä¾‹
elevenlabs_tts = ElevenLabsTTS()

def main():
    """ä¸»å‡½æ•° - CLIå…¥å£"""
    import sys
    
    if len(sys.argv) < 2:
        # æ˜¾ç¤ºçŠ¶æ€
        status = elevenlabs_tts.get_status()
        print("=" * 60)
        print("ğŸ™ï¸ ElevenLabsè¯­éŸ³åˆæˆç³»ç»Ÿ v1.1")
        print("=" * 60)
        print(f"çŠ¶æ€: {status['status']}")
        print(f"APIå¯†é’¥: {'å·²é…ç½®' if status['api_key_configured'] else 'æœªé…ç½®'}")
        print(f"é»˜è®¤å£°éŸ³: {status['default_voice']}")
        print(f"é»˜è®¤æƒ…æ„Ÿ: {status['default_emotion']}")
        print(f"æ¨¡å‹: {status['model']}")
        print(f"ç¼“å­˜ç›®å½•: {status['cache_dir']}")
        print(f"å£°éŸ³æ•°: {status['voices_count']} | æƒ…æ„Ÿæ•°: {status['emotions_count']}")
        print("=" * 60)
        print("\nå¯ç”¨å£°éŸ³:")
        for vid, vinfo in elevenlabs_tts.VOICES.items():
            gender_emoji = "ğŸ‘©" if vinfo['gender'] == 'female' else "ğŸ‘¨"
            print(f"  {gender_emoji} {vid}: {vinfo['style']}")
        print("\n16ç§æƒ…æ„Ÿæ˜ å°„:")
        for category, emotions in elevenlabs_tts.EMOTION_CATEGORIES.items():
            emoji = {'basic': 'ğŸ”µ', 'positive': 'ğŸŸ¢', 'professional': 'ğŸŸ ', 'special': 'ğŸŸ£'}[category]
            print(f"  {emoji} {category}: {', '.join(emotions)}")
        print("=" * 60)
        print("\nç”¨æ³•:")
        print("  python elevenlabs_tts.py status")
        print("  python elevenlabs_tts.py configure <api_key>")
        print("  python elevenlabs_tts.py synthesize 'æ–‡æœ¬' [--voice Bella] [--emotion excited] [--output file.mp3]")
        print("  python elevenlabs_tts.py test-emotions")
        print("  python elevenlabs_tts.py clear-cache")
        return
    
    command = sys.argv[1]
    
    if command == "status":
        print(json.dumps(elevenlabs_tts.get_status(), indent=2, ensure_ascii=False))
    
    elif command == "configure":
        if len(sys.argv) < 3:
            print("âŒ é”™è¯¯: éœ€è¦æä¾›APIå¯†é’¥")
            print("   è·å–åœ°å€: https://elevenlabs.io/app/settings/api-keys")
            return
        api_key = sys.argv[2]
        result = elevenlabs_tts.configure_api_key(api_key)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    elif command == "synthesize":
        if len(sys.argv) < 3:
            print("âŒ é”™è¯¯: éœ€è¦æä¾›æ–‡æœ¬")
            return
        text = sys.argv[2]
        
        # è§£æå¯é€‰å‚æ•°
        voice = elevenlabs_tts.default_voice
        emotion = elevenlabs_tts.default_emotion
        output = None
        
        i = 3
        while i < len(sys.argv):
            if sys.argv[i] == "--voice" and i + 1 < len(sys.argv):
                voice = sys.argv[i + 1]
                i += 2
            elif sys.argv[i] == "--emotion" and i + 1 < len(sys.argv):
                emotion = sys.argv[i + 1]
                i += 2
            elif sys.argv[i] == "--output" and i + 1 < len(sys.argv):
                output = sys.argv[i + 1]
                i += 2
            else:
                i += 1
        
        result = elevenlabs_tts.synthesize(text, voice=voice, emotion=emotion, output_path=output)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    elif command == "test-emotions":
        text = "è¿™æ˜¯ä¸€æ®µæµ‹è¯•è¯­éŸ³ï¼Œç”¨äºéªŒè¯ä¸åŒæƒ…æ„Ÿé£æ ¼çš„æ•ˆæœã€‚"
        if len(sys.argv) > 2:
            text = sys.argv[2]
        results = elevenlabs_tts.test_all_emotions(text)
        print("\nè¯¦ç»†ç»“æœ:")
        print(json.dumps(results, indent=2, ensure_ascii=False))
    
    elif command == "clear-cache":
        result = elevenlabs_tts.clear_cache()
        print(json.dumps(result, indent=2, ensure_ascii=False))
    
    elif command == "voices":
        voices_info = elevenlabs_tts.get_voices()
        print(json.dumps(voices_info, indent=2, ensure_ascii=False))
    
    elif command == "emotions":
        emotions_info = elevenlabs_tts.get_emotions()
        print(json.dumps(emotions_info, indent=2, ensure_ascii=False))
    
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
        print("å¯ç”¨å‘½ä»¤: status, configure, synthesize, test-emotions, clear-cache, voices, emotions")

if __name__ == '__main__':
    main()
